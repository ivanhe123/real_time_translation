{"metadata":{"colab":{"provenance":[{"file_id":"1zTcs_liPMxied_MaISqFi4eIqNeUkBQG","timestamp":1718106180309},{"file_id":"12RrevuwQN7qUOlLY9gY4QPtaciU9-hki","timestamp":1714586724766},{"file_id":"1qa4FaxmXdMEazwKbzhtvGoBsHIG_O4lL","timestamp":1711405217504}],"collapsed_sections":["N_glGfqszRVW","G_pMtTtMuO16","kBjrJUL15pCd"],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8705016,"sourceType":"datasetVersion","datasetId":5221388},{"sourceId":8861592,"sourceType":"datasetVersion","datasetId":5334805},{"sourceId":8862097,"sourceType":"datasetVersion","datasetId":5334887},{"sourceId":8866360,"sourceType":"datasetVersion","datasetId":5336272}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchaudio==2.2.2","metadata":{"execution":{"iopub.status.busy":"2024-07-10T07:34:52.152532Z","iopub.execute_input":"2024-07-10T07:34:52.153311Z","iopub.status.idle":"2024-07-10T07:37:26.724888Z","shell.execute_reply.started":"2024-07-10T07:34:52.153257Z","shell.execute_reply":"2024-07-10T07:37:26.723548Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchaudio==2.2.2\n  Downloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\nCollecting torch==2.2.2 (from torchaudio==2.2.2)\n  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->torchaudio==2.2.2) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->torchaudio==2.2.2) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->torchaudio==2.2.2) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->torchaudio==2.2.2) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->torchaudio==2.2.2) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->torchaudio==2.2.2) (2024.3.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch==2.2.2->torchaudio==2.2.2)\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchaudio==2.2.2)\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.2.2->torchaudio==2.2.2) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.2.2->torchaudio==2.2.2) (1.3.0)\nDownloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.1.2\n    Uninstalling torchaudio-2.1.2:\n      Successfully uninstalled torchaudio-2.1.2\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchaudio-2.2.2 triton-2.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf seamless_communication","metadata":{"execution":{"iopub.status.busy":"2024-07-10T07:37:26.727814Z","iopub.execute_input":"2024-07-10T07:37:26.728262Z","iopub.status.idle":"2024-07-10T07:37:27.874349Z","shell.execute_reply.started":"2024-07-10T07:37:26.728217Z","shell.execute_reply":"2024-07-10T07:37:27.872902Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n!git clone https://github.com/ivanhe123/seamless_communication","metadata":{"execution":{"iopub.status.busy":"2024-07-10T07:37:27.875955Z","iopub.execute_input":"2024-07-10T07:37:27.876313Z","iopub.status.idle":"2024-07-10T07:37:30.726604Z","shell.execute_reply.started":"2024-07-10T07:37:27.876270Z","shell.execute_reply":"2024-07-10T07:37:30.725247Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'seamless_communication'...\nremote: Enumerating objects: 1750, done.\u001b[K\nremote: Counting objects: 100% (1013/1013), done.\u001b[K\nremote: Compressing objects: 100% (533/533), done.\u001b[K\nremote: Total 1750 (delta 719), reused 529 (delta 432), pack-reused 737\u001b[K\nReceiving objects: 100% (1750/1750), 13.87 MiB | 21.01 MiB/s, done.\nResolving deltas: 100% (856/856), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n!pip install ./seamless_communication","metadata":{"id":"opMozo9b7jQk","outputId":"6ed4ea4e-2fbe-42b3-ca04-0581b6799dc6","executionInfo":{"status":"ok","timestamp":1718108184365,"user_tz":-480,"elapsed":31350,"user":{"displayName":"Ivan He","userId":"10616263529827897625"}},"execution":{"iopub.status.busy":"2024-07-10T07:37:30.729334Z","iopub.execute_input":"2024-07-10T07:37:30.729706Z","iopub.status.idle":"2024-07-10T07:38:42.863794Z","shell.execute_reply.started":"2024-07-10T07:37:30.729666Z","shell.execute_reply":"2024-07-10T07:38:42.862615Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Processing ./seamless_communication\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting datasets==2.18.0 (from seamless-communication==1.0.0)\n  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\nCollecting fairseq2==0.2.* (from seamless-communication==1.0.0)\n  Downloading fairseq2-0.2.1-py3-none-any.whl.metadata (1.2 kB)\nCollecting fire (from seamless-communication==1.0.0)\n  Downloading fire-0.6.0.tar.gz (88 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (from seamless-communication==1.0.0) (0.10.2.post1)\nCollecting openai-whisper (from seamless-communication==1.0.0)\n  Downloading openai-whisper-20231117.tar.gz (798 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting simuleval~=1.1.3 (from seamless-communication==1.0.0)\n  Downloading simuleval-1.1.4-py3-none-any.whl.metadata (2.2 kB)\nCollecting sonar-space==0.2.* (from seamless-communication==1.0.0)\n  Downloading sonar_space-0.2.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: soundfile in /opt/conda/lib/python3.10/site-packages (from seamless-communication==1.0.0) (0.12.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from seamless-communication==1.0.0) (1.11.4)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from seamless-communication==1.0.0) (2.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from seamless-communication==1.0.0) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (2.2.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (0.70.16)\nCollecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->seamless-communication==1.0.0)\n  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->seamless-communication==1.0.0) (6.0.1)\nCollecting fairseq2n==0.2.1 (from fairseq2==0.2.*->seamless-communication==1.0.0)\n  Downloading fairseq2n-0.2.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (948 bytes)\nCollecting jiwer~=3.0 (from fairseq2==0.2.*->seamless-communication==1.0.0)\n  Downloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: overrides~=7.3 in /opt/conda/lib/python3.10/site-packages (from fairseq2==0.2.*->seamless-communication==1.0.0) (7.4.0)\nCollecting packaging (from datasets==2.18.0->seamless-communication==1.0.0)\n  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting sacrebleu~=2.3 (from fairseq2==0.2.*->seamless-communication==1.0.0)\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.12.1 in /opt/conda/lib/python3.10/site-packages (from fairseq2==0.2.*->seamless-communication==1.0.0) (2.2.2)\nCollecting torcheval~=0.0.6 (from fairseq2==0.2.*->seamless-communication==1.0.0)\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nCollecting sox (from sonar-space==0.2.*->seamless-communication==1.0.0)\n  Downloading sox-1.5.0.tar.gz (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from sonar-space==0.2.*->seamless-communication==1.0.0) (4.9.0)\nRequirement already satisfied: tbb>=2021.8 in /opt/conda/lib/python3.10/site-packages (from fairseq2n==0.2.1->fairseq2==0.2.*->seamless-communication==1.0.0) (2021.12.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (12.5.82)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from simuleval~=1.1.3->seamless-communication==1.0.0) (8.2.1)\nCollecting pytest-cov (from simuleval~=1.1.3->seamless-communication==1.0.0)\n  Downloading pytest_cov-5.0.0-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: tornado in /opt/conda/lib/python3.10/site-packages (from simuleval~=1.1.3->seamless-communication==1.0.0) (6.3.3)\nCollecting pytest-flake8 (from simuleval~=1.1.3->seamless-communication==1.0.0)\n  Downloading pytest_flake8-1.1.1-py2.py3-none-any.whl.metadata (5.6 kB)\nCollecting textgrid (from simuleval~=1.1.3->seamless-communication==1.0.0)\n  Downloading TextGrid-1.6.1.tar.gz (9.4 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tqdm (from seamless-communication==1.0.0)\n  Downloading tqdm-4.64.1-py2.py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting bitarray==2.6.0 (from simuleval~=1.1.3->seamless-communication==1.0.0)\n  Downloading bitarray-2.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\nCollecting yt-dlp (from simuleval~=1.1.3->seamless-communication==1.0.0)\n  Downloading yt_dlp-2024.7.9-py3-none-any.whl.metadata (169 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.5/169.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from simuleval~=1.1.3->seamless-communication==1.0.0) (0.25.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->seamless-communication==1.0.0) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->seamless-communication==1.0.0) (2.4.0)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa->seamless-communication==1.0.0) (3.0.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa->seamless-communication==1.0.0) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa->seamless-communication==1.0.0) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa->seamless-communication==1.0.0) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa->seamless-communication==1.0.0) (0.58.1)\nRequirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa->seamless-communication==1.0.0) (1.8.1)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa->seamless-communication==1.0.0) (0.3.7)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa->seamless-communication==1.0.0) (0.3)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->seamless-communication==1.0.0) (1.0.7)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile->seamless-communication==1.0.0) (1.16.0)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper->seamless-communication==1.0.0) (10.2.0)\nCollecting tiktoken (from openai-whisper->seamless-communication==1.0.0)\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile->seamless-communication==1.0.0) (2.21)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->seamless-communication==1.0.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->seamless-communication==1.0.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->seamless-communication==1.0.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->seamless-communication==1.0.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->seamless-communication==1.0.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->seamless-communication==1.0.0) (4.0.3)\nRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer~=3.0->fairseq2==0.2.*->seamless-communication==1.0.0) (8.1.7)\nCollecting rapidfuzz<4,>=3 (from jiwer~=3.0->fairseq2==0.2.*->seamless-communication==1.0.0)\n  Downloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa->seamless-communication==1.0.0) (0.41.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa->seamless-communication==1.0.0) (3.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0->seamless-communication==1.0.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0->seamless-communication==1.0.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0->seamless-communication==1.0.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0->seamless-communication==1.0.0) (2024.2.2)\nCollecting portalocker (from sacrebleu~=2.3->fairseq2==0.2.*->seamless-communication==1.0.0)\n  Downloading portalocker-2.10.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu~=2.3->fairseq2==0.2.*->seamless-communication==1.0.0) (2023.12.25)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu~=2.3->fairseq2==0.2.*->seamless-communication==1.0.0) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu~=2.3->fairseq2==0.2.*->seamless-communication==1.0.0) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu~=2.3->fairseq2==0.2.*->seamless-communication==1.0.0) (5.2.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->seamless-communication==1.0.0) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->seamless-communication==1.0.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->seamless-communication==1.0.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->seamless-communication==1.0.0) (2023.4)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->simuleval~=1.1.3->seamless-communication==1.0.0) (2.0.0)\nRequirement already satisfied: pluggy<2.0,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest->simuleval~=1.1.3->seamless-communication==1.0.0) (1.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->simuleval~=1.1.3->seamless-communication==1.0.0) (1.2.0)\nRequirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->simuleval~=1.1.3->seamless-communication==1.0.0) (2.0.1)\nCollecting coverage>=5.2.1 (from coverage[toml]>=5.2.1->pytest-cov->simuleval~=1.1.3->seamless-communication==1.0.0)\n  Downloading coverage-7.5.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\nRequirement already satisfied: flake8>=4.0 in /opt/conda/lib/python3.10/site-packages (from pytest-flake8->simuleval~=1.1.3->seamless-communication==1.0.0) (7.0.0)\nRequirement already satisfied: brotli in /opt/conda/lib/python3.10/site-packages (from yt-dlp->simuleval~=1.1.3->seamless-communication==1.0.0) (1.1.0)\nCollecting mutagen (from yt-dlp->simuleval~=1.1.3->seamless-communication==1.0.0)\n  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\nCollecting pycryptodomex (from yt-dlp->simuleval~=1.1.3->seamless-communication==1.0.0)\n  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: websockets>=12.0 in /opt/conda/lib/python3.10/site-packages (from yt-dlp->simuleval~=1.1.3->seamless-communication==1.0.0) (12.0)\nRequirement already satisfied: mccabe<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from flake8>=4.0->pytest-flake8->simuleval~=1.1.3->seamless-communication==1.0.0) (0.7.0)\nRequirement already satisfied: pycodestyle<2.12.0,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from flake8>=4.0->pytest-flake8->simuleval~=1.1.3->seamless-communication==1.0.0) (2.11.1)\nRequirement already satisfied: pyflakes<3.3.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from flake8>=4.0->pytest-flake8->simuleval~=1.1.3->seamless-communication==1.0.0) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12.1->fairseq2==0.2.*->seamless-communication==1.0.0) (1.3.0)\nDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fairseq2-0.2.1-py3-none-any.whl (191 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.8/191.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sonar_space-0.2.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fairseq2n-0.2.1-cp310-cp310-manylinux2014_x86_64.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading simuleval-1.1.4-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitarray-2.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiwer-3.0.4-py3-none-any.whl (21 kB)\nUsing cached packaging-23.2-py3-none-any.whl (53 kB)\nDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytest_cov-5.0.0-py3-none-any.whl (21 kB)\nDownloading pytest_flake8-1.1.1-py2.py3-none-any.whl (6.6 kB)\nDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading yt_dlp-2024.7.9-py3-none-any.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading coverage-7.5.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (233 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.1/233.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.0-py3-none-any.whl (18 kB)\nDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: seamless-communication, fire, openai-whisper, sox, textgrid\n  Building wheel for seamless-communication (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seamless-communication: filename=seamless_communication-1.0.0-py3-none-any.whl size=222081 sha256=d8b2152e0272f13821ab1133ce797428119e125f00bce11c77e69667f53476b8\n  Stored in directory: /tmp/pip-ephem-wheel-cache-n7mekrwq/wheels/f0/cf/23/abec8184257cf69b02e15bebac2f2ad64cd2876e4f48b471cf\n  Building wheel for fire (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=a1d29b95d027ddd7d3ffef799beff8bc91cb848e6b2ce03f658d487a76b2730d\n  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=96a6e525469ef90e8da29fb7abb136cb9e5b850757039b75f4cee82eddd78e94\n  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n  Building wheel for sox (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40037 sha256=1abe2ddba459502d68daae3b08c74b4af875f63eb9e4fb27c0e7386f387be0ad\n  Stored in directory: /root/.cache/pip/wheels/74/e7/7b/8033be3ec5e4994595d01269fc9657c8fd83a0dcbf8536666a\n  Building wheel for textgrid (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for textgrid: filename=TextGrid-1.6.1-py3-none-any.whl size=10147 sha256=ff8e594e23b2dcb7b05856ff9ad7c44687e2a5efd39385d68f3584d0338115f1\n  Stored in directory: /root/.cache/pip/wheels/23/41/f2/e2ef1817bd163de3c21dd078966bdd71bd5c4455841f4ec016\nSuccessfully built seamless-communication fire openai-whisper sox textgrid\nInstalling collected packages: textgrid, bitarray, tqdm, torcheval, sox, rapidfuzz, pycryptodomex, portalocker, packaging, mutagen, fsspec, fire, coverage, yt-dlp, tiktoken, sacrebleu, jiwer, pytest-flake8, pytest-cov, simuleval, openai-whisper, fairseq2n, datasets, fairseq2, sonar-space, seamless-communication\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.66.4\n    Uninstalling tqdm-4.66.4:\n      Successfully uninstalled tqdm-4.66.4\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.3.1\n    Uninstalling fsspec-2024.3.1:\n      Successfully uninstalled fsspec-2024.3.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.19.2\n    Uninstalling datasets-2.19.2:\n      Successfully uninstalled datasets-2.19.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.1 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nfeaturetools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.64.1 which is incompatible.\nfitter 1.7.0 requires tqdm<5.0.0,>=4.65.1, but you have tqdm 4.64.1 which is incompatible.\ngcsfs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2024.2.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\ns3fs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2024.2.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitarray-2.6.0 coverage-7.5.4 datasets-2.18.0 fairseq2-0.2.1 fairseq2n-0.2.1 fire-0.6.0 fsspec-2024.2.0 jiwer-3.0.4 mutagen-1.47.0 openai-whisper-20231117 packaging-23.2 portalocker-2.10.0 pycryptodomex-3.20.0 pytest-cov-5.0.0 pytest-flake8-1.1.1 rapidfuzz-3.9.4 sacrebleu-2.4.2 seamless-communication-1.0.0 simuleval-1.1.4 sonar-space-0.2.1 sox-1.5.0 textgrid-1.6.1 tiktoken-0.7.0 torcheval-0.0.7 tqdm-4.64.1 yt-dlp-2024.7.9\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install whisper_normalizer","metadata":{"execution":{"iopub.status.busy":"2024-07-10T07:38:42.865618Z","iopub.execute_input":"2024-07-10T07:38:42.866050Z","iopub.status.idle":"2024-07-10T07:38:58.108779Z","shell.execute_reply.started":"2024-07-10T07:38:42.865999Z","shell.execute_reply":"2024-07-10T07:38:58.107619Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting whisper_normalizer\n  Downloading whisper_normalizer-0.0.10-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from whisper_normalizer) (10.2.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from whisper_normalizer) (2023.12.25)\nDownloading whisper_normalizer-0.0.10-py3-none-any.whl (23 kB)\nInstalling collected packages: whisper_normalizer\nSuccessfully installed whisper_normalizer-0.0.10\n","output_type":"stream"}]},{"cell_type":"code","source":"#!rm -f /kaggle/working/checkpoints","metadata":{"execution":{"iopub.status.busy":"2024-07-10T07:38:58.110499Z","iopub.execute_input":"2024-07-10T07:38:58.110907Z","iopub.status.idle":"2024-07-10T07:38:58.116350Z","shell.execute_reply.started":"2024-07-10T07:38:58.110866Z","shell.execute_reply":"2024-07-10T07:38:58.115207Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/cheksd","metadata":{"id":"wkSCifeeh8I-","executionInfo":{"status":"ok","timestamp":1718108184366,"user_tz":-480,"elapsed":11,"user":{"displayName":"Ivan He","userId":"10616263529827897625"}},"outputId":"07c757ca-9c0c-4878-a344-1e8de142c8e5","execution":{"iopub.status.busy":"2024-07-10T07:38:58.117607Z","iopub.execute_input":"2024-07-10T07:38:58.117967Z","iopub.status.idle":"2024-07-10T07:38:59.290035Z","shell.execute_reply.started":"2024-07-10T07:38:58.117937Z","shell.execute_reply":"2024-07-10T07:38:59.288610Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!mkdir -p fleurs\n!m4t_prepare_dataset \\\n    --name google/fleurs \\\n    --split train \\\n    --source_lang zh \\\n    --target_lang eng \\\n    --save_dir fleurs","metadata":{"execution":{"iopub.status.busy":"2024-07-10T07:39:22.410951Z","iopub.execute_input":"2024-07-10T07:39:22.411397Z","iopub.status.idle":"2024-07-10T07:55:01.926872Z","shell.execute_reply.started":"2024-07-10T07:39:22.411351Z","shell.execute_reply":"2024-07-10T07:55:01.925695Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading the checkpoint of xlsr2_1b_v2...\n100%|███████████████████████████████████████| 3.60G/3.60G [00:16<00:00, 232MB/s]\n/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\nDownloading the checkpoint of https://dl.fbaipublicfiles.com/seamlessM4T/models/unit_extraction/kmeans_10k.npy...\n100%|██████████████████████████████████████| 48.8M/48.8M [00:02<00:00, 20.9MB/s]\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\nDownloading builder script: 100%|██████████| 12.6k/12.6k [00:00<00:00, 23.8MB/s]\nDownloading readme: 100%|██████████████████| 13.3k/13.3k [00:00<00:00, 24.7MB/s]\nDownloading data: 100%|████████████████████| 1.38G/1.38G [00:30<00:00, 44.7MB/s]\nDownloading data: 100%|██████████████████████| 171M/171M [00:04<00:00, 39.6MB/s]\nDownloading data: 100%|██████████████████████| 290M/290M [00:06<00:00, 44.6MB/s]\nDownloading data: 100%|████████████████████| 1.41M/1.41M [00:00<00:00, 10.9MB/s]\nDownloading data: 100%|██████████████████████| 213k/213k [00:00<00:00, 5.54MB/s]\nDownloading data: 100%|██████████████████████| 368k/368k [00:00<00:00, 6.68MB/s]\nGenerating train split: 2602 examples [00:28, 92.36 examples/s] \nGenerating validation split: 394 examples [00:03, 100.61 examples/s]\nGenerating test split: 647 examples [00:06, 97.85 examples/s] \n..loaded 100 target samples\n..loaded 200 target samples\n..loaded 300 target samples\n..loaded 400 target samples\n..loaded 500 target samples\n..loaded 600 target samples\n..loaded 700 target samples\n..loaded 800 target samples\n..loaded 900 target samples\n..loaded 1000 target samples\n..loaded 1100 target samples\n..loaded 1200 target samples\n..loaded 1300 target samples\n..loaded 1400 target samples\n..loaded 1500 target samples\n..loaded 1600 target samples\n..loaded 1700 target samples\n..loaded 1800 target samples\n..loaded 1900 target samples\n..loaded 2000 target samples\n..loaded 2100 target samples\n..loaded 2200 target samples\n..loaded 2300 target samples\n..loaded 2400 target samples\n..loaded 2500 target samples\n..loaded 2600 target samples\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\nDownloading data: 100%|████████████████████| 1.77G/1.77G [00:45<00:00, 38.7MB/s]\nDownloading data: 100%|██████████████████████| 217M/217M [00:04<00:00, 47.4MB/s]\nDownloading data: 100%|██████████████████████| 525M/525M [00:11<00:00, 47.4MB/s]\nDownloading data: 100%|████████████████████| 1.66M/1.66M [00:00<00:00, 21.6MB/s]\nDownloading data: 100%|██████████████████████| 205k/205k [00:00<00:00, 3.48MB/s]\nDownloading data: 100%|██████████████████████| 491k/491k [00:00<00:00, 5.70MB/s]\nGenerating train split: 3246 examples [00:35, 91.55 examples/s] \nGenerating validation split: 409 examples [00:04, 96.23 examples/s] \nGenerating test split: 945 examples [00:11, 79.23 examples/s] \n..loaded 100 source samples\n..loaded 200 source samples\n..loaded 300 source samples\n..loaded 400 source samples\n..loaded 500 source samples\n..loaded 600 source samples\n..loaded 700 source samples\n..loaded 800 source samples\n..loaded 900 source samples\n..loaded 1000 source samples\n..loaded 1100 source samples\n..loaded 1200 source samples\n..loaded 1300 source samples\n..loaded 1400 source samples\n..loaded 1500 source samples\n..loaded 1600 source samples\n..loaded 1700 source samples\n..loaded 1800 source samples\n..loaded 1900 source samples\n..loaded 2000 source samples\n..loaded 2100 source samples\n..loaded 2200 source samples\n..loaded 2300 source samples\n..loaded 2400 source samples\n..loaded 2500 source samples\n..loaded 2600 source samples\n..loaded 2700 source samples\n..loaded 2800 source samples\n..loaded 2900 source samples\n..loaded 3000 source samples\n..loaded 3100 source samples\n..loaded 3200 source samples\nSaved 3178 samples for split=train to fleurs/train_manifest.json\nManifest saved to: fleurs/train_manifest.json\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!m4t_prepare_dataset \\\n    --name google/fleurs \\\n    --split validation \\\n    --source_lang zh \\\n    --target_lang eng \\\n    --save_dir fleurs","metadata":{"execution":{"iopub.status.busy":"2024-07-10T07:55:01.929233Z","iopub.execute_input":"2024-07-10T07:55:01.929631Z","iopub.status.idle":"2024-07-10T07:57:04.356821Z","shell.execute_reply.started":"2024-07-10T07:55:01.929593Z","shell.execute_reply":"2024-07-10T07:57:04.355547Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Using the cached checkpoint of xlsr2_1b_v2. Set `force` to `True` to download again.\n/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\nUsing the cached checkpoint of https://dl.fbaipublicfiles.com/seamlessM4T/models/unit_extraction/kmeans_10k.npy. Set `force` to `True` to download again.\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n..loaded 100 target samples\n..loaded 200 target samples\n..loaded 300 target samples\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n..loaded 100 source samples\n..loaded 200 source samples\n..loaded 300 source samples\n..loaded 400 source samples\nSaved 409 samples for split=validation to fleurs/validation_manifest.json\nManifest saved to: fleurs/validation_manifest.json\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Model Layers","metadata":{"id":"kBjrJUL15pCd"}},{"cell_type":"markdown","source":"```\nmodel\nmodel.speech_encoder_frontend\nmodel.speech_encoder\nmodel.speech_encoder.inner\nmodel.speech_encoder.inner.layers\nmodel.speech_encoder.inner.layers.0\nmodel.speech_encoder.inner.layers.1\nmodel.speech_encoder.inner.layers.2\nmodel.speech_encoder.inner.layers.3\nmodel.speech_encoder.inner.layers.4\nmodel.speech_encoder.inner.layers.5\nmodel.speech_encoder.inner.layers.6\nmodel.speech_encoder.inner.layers.7\nmodel.speech_encoder.inner.layers.8\nmodel.speech_encoder.inner.layers.9\nmodel.speech_encoder.inner.layers.10\nmodel.speech_encoder.inner.layers.11\nmodel.speech_encoder.inner_layer_norm\nmodel.speech_encoder.proj1\nmodel.speech_encoder.activation\nmodel.speech_encoder.proj2\nmodel.speech_encoder.adaptor_layers\nmodel.speech_encoder.adaptor_layers.0\nmodel.speech_encoder.layer_norm\nmodel.text_encoder_frontend\nmodel.text_decoder\nmodel.text_decoder.layers\nmodel.text_decoder.layers.0\nmodel.text_decoder.layers.1\nmodel.text_decoder.layers.2\nmodel.text_decoder.layers.3\nmodel.text_decoder.layers.4\nmodel.text_decoder.layers.5\nmodel.text_decoder.layers.6\nmodel.text_decoder.layers.7\nmodel.text_decoder.layers.8\nmodel.text_decoder.layers.9\nmodel.text_decoder.layers.10\nmodel.text_decoder.layers.11\nmodel.text_decoder.layer_norm\nmodel.final_proj\n```","metadata":{"id":"Untp6JES5r14"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.distributed as dist\nprint(torch.distributed.is_available())\nprint(torch.distributed.is_nccl_available())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.distributed.init_process_group(backend=\"nccl\", rank=0, world_size=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!RANK='0'\n!LOCAL_RANK='0'\n!WORLD_SIZE='3'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!export RANK\n!export LOCAL_RANK\n!export WORLD_SIZE","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T07:57:58.646308Z","iopub.execute_input":"2024-07-10T07:57:58.647367Z","iopub.status.idle":"2024-07-10T07:58:00.431110Z","shell.execute_reply.started":"2024-07-10T07:57:58.647319Z","shell.execute_reply":"2024-07-10T07:58:00.430093Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!m4t_finetune \\\n      --train_dataset /kaggle/working/fleurs/train_manifest.json \\\n      --eval_dataset /kaggle/working/fleurs/validation_manifest.json \\\n      --batch_size 6 \\\n      --eval_steps 1000 \\\n      --learning_rate 0.00008 \\\n      --patience 4 \\\n      --save_model_to /kaggle/working/cheksd/expt4_m4tM.pt \\\n      --model_name seamlessM4T_medium \\\n      --max_epochs 15 \\\n      --freeze_layers \\\n          model.speech_encoder_frontend \\\n          model.speech_encoder \\\n          model.text_decoder.layers.0 \\\n          model.text_decoder.layers.1 \\\n          model.text_decoder.layers.2 \\\n          model.text_decoder.layers.3 \\\n          model.text_decoder.layers.4 \\\n          model.text_decoder.layers.5 \\\n          model.text_decoder.layers.6 \\\n          model.text_decoder.layers.7 \\\n          model.text_decoder.layers.8 \\\n          model.text_decoder.layers.9 \\\n          model.text_decoder.layer_norm \\\n          model.final_proj \\\n      --mode \\\n          SPEECH_TO_SPEECH","metadata":{"id":"AwgB8yoOXbGs","execution":{"iopub.status.busy":"2024-07-10T07:58:02.166981Z","iopub.execute_input":"2024-07-10T07:58:02.167537Z","iopub.status.idle":"2024-07-10T09:45:23.124086Z","shell.execute_reply.started":"2024-07-10T07:58:02.167483Z","shell.execute_reply":"2024-07-10T09:45:23.122805Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Cannot init disributed context, as environment varaibles are not set.\nDownloading the tokenizer of seamlessM4T_medium...\n100%|██████████████████████████████████████| 4.63M/4.63M [00:00<00:00, 18.7MB/s]\nDownloading the checkpoint of seamlessM4T_medium...\n100%|██████████████████████████████████████| 6.37G/6.37G [02:28<00:00, 46.0MB/s]\n/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\nTraining Steps: 100%|█████████████████████████| 530/530 [07:58<00:00,  1.11it/s]\nSaving model\nTraining Steps:  88%|██████████████████████   | 469/530 [07:02<00:59,  1.03it/s]Saving model\nTraining Steps: 100%|█████████████████████████| 530/530 [09:36<00:00,  1.09s/it]\nSaving model\nTraining Steps: 100%|█████████████████████████| 530/530 [07:54<00:00,  1.12it/s]\nSaving model\nTraining Steps:  77%|███████████████████▎     | 409/530 [06:10<02:00,  1.01it/s]Saving model\nTraining Steps: 100%|█████████████████████████| 530/530 [09:36<00:00,  1.09s/it]\nSaving model\nTraining Steps: 100%|█████████████████████████| 530/530 [07:56<00:00,  1.11it/s]\nSaving model\nTraining Steps: 100%|█████████████████████████| 530/530 [09:09<00:00,  1.04s/it]\nSaving model\nTraining Steps: 100%|█████████████████████████| 530/530 [07:56<00:00,  1.11it/s]\nSaving model\nTraining Steps: 100%|█████████████████████████| 530/530 [09:10<00:00,  1.04s/it]\nSaving model\nTraining Steps: 100%|█████████████████████████| 530/530 [07:54<00:00,  1.12it/s]\nSaving model\nTraining Steps: 100%|█████████████████████████| 530/530 [09:07<00:00,  1.03s/it]\nSaving model\nTraining Steps: 100%|█████████████████████████| 530/530 [07:56<00:00,  1.11it/s]\nSaving model\nTraining Steps:  32%|███████▉                 | 169/530 [03:55<08:22,  1.39s/it]\nSaving model\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!m4t_finetune \\\n  --train_dataset /kaggle/working/fleurs/train_manifest.json \\\n  --eval_dataset /kaggle/working/fleurs/validation_manifest.json \\\n  --batch_size 6 \\\n  --eval_steps 1000 \\\n  --learning_rate 0.00008 \\\n  --patience 4 \\\n  --save_model_to /kaggle/working/cheksd/expt4_m4tM.pt \\\n  --model_name seamlessM4T_medium \\\n  --max_epochs 10\\\n  --freeze_layers \\\n      model.speech_encoder.inner \\\n      model.speech_encoder.inner.layers \\\n      model.speech_encoder.inner.layers.0 \\\n      model.speech_encoder.inner.layers.1 \\\n      model.speech_encoder.inner.layers.2 \\\n      model.speech_encoder.inner.layers.3 \\\n      model.speech_encoder.inner.layers.4 \\\n      model.speech_encoder.inner.layers.5 \\\n      model.speech_encoder.inner.layers.6 \\\n      model.speech_encoder.inner.layers.7 \\\n      model.speech_encoder.inner.layers.8 \\\n      model.speech_encoder.inner.layers.9 \\\n      model.speech_encoder.inner.layers.10 \\\n      model.speech_encoder.inner.layers.11 \\\n      model.speech_encoder.inner_layer_norm \\\n      model.speech_encoder.proj1 \\\n      model.speech_encoder.activation \\\n      model.speech_encoder.proj2 \\\n      model.speech_encoder.adaptor_layers \\\n      model.speech_encoder.adaptor_layers.0 \\\n      model.speech_encoder.layer_norm \\\n      model.text_encoder_frontend \\\n      model.text_decoder \\\n      model.text_decoder.layers \\\n      model.text_decoder.layers.10 \\\n      model.text_decoder.layers.11 \\\n\n  --mode \\\n      SPEECH_TO_SPEECH","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!zip download_checkpoints.zip /kaggle/working/checkpoint","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from IPython.display import FileLink \nFileLink(r'download_checkpoints.zip')\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"cellView":"form","id":"On6CJ8O7XbGt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Expt 4: Unfreeze decoder and few last layers of encoder","metadata":{"id":"RmXC-14HXwA9"}},{"cell_type":"code","source":"","metadata":{"id":"FRhA8q1bXwA9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Mini Evaluation\nMAX_SAMPLES = 300 # @param {type:\"number\"}\nCHECKPOINT_PATH = \"/kaggle/working/cheksd/expt4_m4tM.pt\" # @param {type:\"string\"}\nDATASET_SPLIT = \"s\" # @param {type:\"string\"}\n\nimport os\nimport torch\nimport logging\nfrom tqdm import tqdm\nfrom datasets import load_dataset\nfrom typing import Tuple, Iterable, Dict, Any\nfrom whisper_normalizer.english import EnglishTextNormalizer\nfrom seamless_communication.models.unity import UnitYModel\nfrom seamless_communication.inference import Translator\nfrom jiwer import wer\ntorch.cuda.empty_cache()\n\ndef _iterate_ds(card: str, subset: str, split: str) -> Iterable[Tuple[torch.Tensor, str]]:\n    ds = load_dataset(\n        card,\n        subset,\n        token=token,\n        split=split,\n        streaming=True,\n        trust_remote_code=True,\n        cache_dir=f\"google/{subset}\")\n\n    for idx, item in enumerate(ds):\n        if idx >= MAX_SAMPLES:\n            break\n        assert item[\"audio\"][\"sampling_rate\"] == 16000\n        yield (torch.from_numpy(item[\"audio\"][\"array\"]), item[\"text\"])\n\n\ndef eval(translator: Translator, normalize = (False, False)) -> float:\n    references = []\n    predictions = []\n    ds = _iterate_ds(\"google/fleurs\", DATASET_SPLIT, \"test\")\n    english_normalizer = EnglishTextNormalizer()\n    norm_ref, norm_pred = normalize\n\n    for idx, (wav, text) in tqdm(enumerate(ds), desc=\"Mini Evaluation\"):\n        if norm_ref:\n          text = english_normalizer(text)\n        if not text:\n          text = \".\"\n        references.append(text)\n\n        prediction = str(\n            translator.predict(\n                input=wav,\n                task_str=\"s2tt\",\n                tgt_lang=\"eng\",\n                src_lang=\"eng\",\n            )[0][0]\n        )\n        if norm_pred:\n          prediction = english_normalizer(prediction)\n        predictions.append(prediction)\n    return wer(reference=references, hypothesis=predictions)\n\n\ndef load_checkpoint(model: UnitYModel, path: str, device = \"cpu\") -> None:\n    state_dict = torch.load(path, map_location=device)[\"model\"]\n\n    def _select_keys(state_dict: Dict[str, Any], prefix: str) -> Dict[str, Any]:\n        return {key.replace(prefix, \"\"): value for key, value in state_dict.items() if key.startswith(prefix)}\n\n    model.speech_encoder_frontend.load_state_dict(_select_keys(state_dict, \"model.speech_encoder_frontend.\"))\n    model.speech_encoder.load_state_dict(_select_keys(state_dict, \"model.speech_encoder.\"))\n\n    assert model.text_decoder_frontend is not None\n    model.text_decoder_frontend.load_state_dict(_select_keys(state_dict, \"model.text_decoder_frontend.\"))\n\n    assert model.text_decoder is not None\n    model.text_decoder.load_state_dict(_select_keys(state_dict, \"model.text_decoder.\"))\n\n    assert model.final_proj is not None\n    model.final_proj.load_state_dict(_select_keys(state_dict, \"model.final_proj.\"))\n\ntranslator = Translator(\n  model_name_or_card=\"seamlessM4T_medium\",\n  vocoder_name_or_card=None,\n  device=torch.device(\"cuda\"))\n\n\nload_checkpoint(translator.model, CHECKPOINT_PATH, torch.device(\"cuda\"))\n\ntuned_wer = eval(translator)\nprint(f\"WER tuned: {tuned_wer:.4f}\")\n\n# Clear CUDA memory\ndel translator\ntorch.cuda.empty_cache()","metadata":{"cellView":"form","id":"tCb2r14gXwA9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Expt 5: Unfreeze last 6 layers of decoder","metadata":{"id":"AGmQdlST7nRJ"}}]}
